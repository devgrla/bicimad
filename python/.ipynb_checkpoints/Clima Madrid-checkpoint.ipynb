{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clima de Madrid diario -  API de AEMET.\n",
    "\n",
    "Vamos a necesitar esta información para el TFM, para poder cruzar la relación entre el clima y el uso de las bicicletas. La idea además de guardar estos datos en memoria, es volcarlos a la Base de datos armada con este fin.\n",
    "\n",
    "En otro notebook se cruza y se analiza la información obtenida aquí con la del uso de bicicletas.\n",
    "\n",
    "Se extrae la informacion desde el 2015 para la `estación número 3195 que es la correspondiente a Retiro`\n",
    "\n",
    "La API es ofrecida por la AEMET. Se puede obtener más información en este [Link](https://opendata.aemet.es/dist/index.html?#/valores-climatologicos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos una key de AEMET para utilizar la API. Ésta devuelve la información diaria del clima como lluvias, temperaturas, vientos y presión atmosférica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJnYXN0b25sZWduYW5pQGdtYWlsLmNvbSIsImp0aSI6ImIyZDhmNDE2LTE3MDItNDM2YS1hODlkLTQ2NTVjMDA3YmUxNiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNTQ0ODI1NjA1LCJ1c2VySWQiOiJiMmQ4ZjQxNi0xNzAyLTQzNmEtYTg5ZC00NjU1YzAwN2JlMTYiLCJyb2xlIjoiIn0.ASVNRgmmUnZruDkbSHFYtagQNC4qW5N2WqgLtqzTvEM'\n",
    "url = 'https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos/fechaini/{0}/fechafin/{1}/estacion/{2}/'\n",
    "params = {'api_key': api_key}\n",
    "station = 3195 #Estacion de Retiro (la que vamos a utilizar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las funciones a utilizar en la limpieza y transformación de datos.\n",
    "Tiene que ver con la conversión de texto a números (reemplazando , por .) y el cast de fechas para que tengan el formato correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_number(number):\n",
    "    try:\n",
    "        if number:\n",
    "            number = number.replace(',','.')\n",
    "            return float(number)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def cast_date(date):\n",
    "    return datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "def cast_time(time):\n",
    "    try:\n",
    "        return datetime.strptime(time, '%H:%M').time()\n",
    "    except:\n",
    "        return datetime.strptime('00:00', '%H:%M').time()\n",
    "\n",
    "def get_properties(dict_weather_day):\n",
    "    #extraccion de propiedades\n",
    "    date = cast_date(dict_weather_day['fecha'])\n",
    "    print('Analizando datos fecha: ' + dict_weather_day['fecha'])\n",
    "    try:  \n",
    "        temp_med = cast_number(dict_weather_day['tmed'])\n",
    "    except: \n",
    "        temp_med = 0\n",
    "    try:\n",
    "        precipitation = cast_number(dict_weather_day['prec'])\n",
    "    except:\n",
    "        precipitation = 0\n",
    "    try:\n",
    "        temp_min = cast_number(dict_weather_day['tmin'])\n",
    "    except:\n",
    "        temp_min = 0\n",
    "    try:\n",
    "        temp_max = cast_number(dict_weather_day['tmax'])\n",
    "    except:\n",
    "        temp_max = 0\n",
    "    try:\n",
    "        wind_speed = cast_number(dict_weather_day['velmedia'])\n",
    "    except:\n",
    "        wind_speed = 0\n",
    "    try:\n",
    "        wind_speed_max = cast_number(dict_weather_day['racha'])\n",
    "    except:\n",
    "        wind_speed_max = 0\n",
    "    try:\n",
    "        hour_temp_min = cast_time(dict_weather_day['horatmin'])\n",
    "    except:\n",
    "        hour_temp_min = 0\n",
    "    try:\n",
    "        hour_temp_max = cast_time(dict_weather_day['horatmax'])\n",
    "    except:\n",
    "        hour_temp_max = 0\n",
    "      \n",
    "    properties = {\n",
    "            'date': date, \n",
    "            'temp_media': temp_med, \n",
    "            'precipitation': precipitation, \n",
    "            'temp_min': temp_min, \n",
    "            'temp_max': temp_max, \n",
    "            'wind_speed': wind_speed,\n",
    "            'wind_speed_max': wind_speed_max,\n",
    "            'hour_temp_min': hour_temp_min,\n",
    "            'hour_temp_max': hour_temp_max\n",
    "        }\n",
    "    \n",
    "    return properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opciones para obtener la información del clima\n",
    "\n",
    "Para probar los datos hay dos opciones que se describen a continuación.\n",
    "\n",
    "### Opción 1\n",
    "\n",
    "A continuación está la función que ejecuta la api del clima sobre un período de fechas establecidos y la almacena en un dataframe. Este código ya fue ejecutado para todo 2015,2016,2017, 2018 y lo que va del 2019. Pero obviamente tarda un poco. Se puede probar cambiando el período que se quiere analizar en las variables **min_date_to_check** y **max_date_to_check** y probar con esos datos.\n",
    "\n",
    "### Opción 2\n",
    "\n",
    "Se puede acceder a los datos que ya obtuvimos, desde un archivo .csv que se encuentra en la carpeta dat y se llama **all_weather_data.csv** que ya existe y contiene toda la información desde el 2015 a la fecha.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opción 1\n",
    "\n",
    "Itera sobre la API y descarga la información en un .csv. Se define el periodo por el que se quiere consultar al inicio de la consulta.\n",
    "\n",
    "Se tuvo que hacer un time.sleep entre cada iteración porque de lo contrario la api devolvía error (Too many requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_day = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date_to_check = datetime(2019,1,4)\n",
    "max_date_to_check = datetime(2019,2,4)\n",
    "day_count = (max_date_to_check - min_date_to_check).days + 1\n",
    "\n",
    "#Por cada fecha entre el máximo y el mínimo hago la llamada a la API\n",
    "for single_date in (min_date_to_check + timedelta(n) for n in range(day_count)):\n",
    "    \n",
    "    time.sleep(4) #Es necesario para que no empiece a dar problemas de \"Too many requests\" si se buscan muchos datos.\n",
    "    \n",
    "    single_date_formatted = datetime.strftime(single_date, '%Y-%m-%d' + 'T00:00:00UTC')\n",
    "    response = requests.get(url.format(single_date_formatted, single_date_formatted, str(station)), params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data_url = response.json()['datos']\n",
    "        #invoco a url de datos\n",
    "        response_data = requests.get(data_url)\n",
    "        response_data_json = response_data.json()\n",
    "        results_per_day.append(get_properties(response_data_json[0]))\n",
    "    else:\n",
    "        print('Código de respuesta erróneo para la fecha: {0}, código: {1} '\n",
    "              .format(single_date_formatted, str(response.status_code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.DataFrame(results_per_day)\n",
    "weather_data.to_csv('../dat/weather_data.csv') #Cambiar nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opción 2\n",
    "\n",
    "Levanta la información utilizando el csv donde ya se descargó toda la información para esos años. Si se quiere utilizar el archivo que contiene la info desde el 2015 hasta la fecha usar `**all_weather_data.csv**`. De lo contrario utilizar el archivo que generó en la opción 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('../dat/all_weather_data.csv', sep = ',', index_col = 0)\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego columnas de interés para utilizar luego en la visualización\n",
    "\n",
    "Agrego columnas como mes, año y estación para poder responder a diferentes preguntas con los gráficos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_copy = weather_data.copy()\n",
    "def get_season(row):\n",
    "    date = row.date\n",
    "    if date >= datetime(date.year, 3, 21) and date <= datetime(date.year, 6, 20):\n",
    "        return 'Primavera'\n",
    "    elif date >= datetime(date.year, 6, 21) and date <= datetime(date.year, 9 , 20):\n",
    "        return 'Verano'\n",
    "    elif date >= datetime(date.year, 9, 21) and date <= datetime(date.year, 12 , 20):\n",
    "        return 'Otoño'\n",
    "    else:\n",
    "        return 'Invierno'\n",
    "\n",
    "weather_data_copy['date'] = weather_data_copy.date.apply(cast_date)\n",
    "weather_data_copy['year'] = weather_data_copy.apply(lambda fila: fila.date.year, axis = 1)\n",
    "weather_data_copy['month'] = weather_data_copy.apply(lambda fila: fila.date.month, axis = 1)\n",
    "weather_data_copy['season'] = weather_data_copy.apply(get_season, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estructura de la tabla queda de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Día que más llovió desde el 2015? (en mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_copy[weather_data_copy.precipitation == weather_data_copy.precipitation.max()].iloc[:,[0,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Día más frio y caluroso desde el 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = weather_data_copy[(weather_data_copy.temp_min == weather_data_copy.temp_min.min())].iloc[:, [0,4,6]] \n",
    "data_max = weather_data_copy[(weather_data_copy.temp_max == weather_data_copy.temp_max.max())].iloc[:, [0,4,6]] \n",
    "\n",
    "print('Dia más frío: ' + data.iloc[0].date.strftime('%d/%m/%Y') + ' con una temperatura mínima de: ' + str(data.iloc[0].temp_min) + ' grados.')\n",
    "print(' ')\n",
    "print('Dia más caluroso: ' + data_max.iloc[0].date.strftime('%d/%m/%Y') + ' con una temperatura máxima de: ' + str(data_max.iloc[0].temp_max) + ' grados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Día con la racha de viento más grande?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_copy[weather_data_copy.wind_speed_max == weather_data_copy.wind_speed_max.max()].iloc[:,[0,8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización datos relacionados al clima\n",
    "\n",
    "Agrego librerias necesarias para los gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 14, 10\n",
    "sns.set_context('paper', font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "sns.despine()\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución de la temperatura media \n",
    "\n",
    "Por ejemplo queremos ver como es la distribución de la temperatura media en Madrid y como ha cambiado en los últimos años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribución de la temperatura media 2018\n",
    "tmp = weather_data_copy[weather_data_copy.year == 2018]\n",
    "out = sns.distplot(weather_data_copy[weather_data_copy.year == 2018].temp_media, hist=False, kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"2018\"})\n",
    "out = sns.distplot(weather_data_copy[weather_data_copy.year == 2017].temp_media, hist=False, kde_kws={\"color\": \"y\", \"lw\": 3, \"label\": \"2017\"})\n",
    "out = sns.distplot(weather_data_copy[weather_data_copy.year == 2016].temp_media, hist=False, kde_kws={\"color\": \"g\", \"lw\": 3, \"label\": \"2016\"})\n",
    "out = sns.distplot(weather_data_copy[weather_data_copy.year == 2015].temp_media, hist=False, kde_kws={\"color\": \"m\", \"lw\": 3, \"label\": \"2015\"})\n",
    "\n",
    "plt.axvline(weather_data_copy[weather_data_copy.year == 2018].temp_media.mean(), 1,0, color= \"k\", linestyle='--')\n",
    "plt.axvline(weather_data_copy[weather_data_copy.year == 2017].temp_media.mean(), 1, 0, color= \"y\", linestyle='--')\n",
    "plt.axvline(weather_data_copy[weather_data_copy.year == 2016].temp_media.mean(), 1, 0, color= \"g\", linestyle='--')\n",
    "plt.xlabel('Temperatura media')\n",
    "plt.title('Distribución Temperatura media - 2015 a 2018')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las lineas verticales corresponden a las medias anuales de temperatura. Vemos que no siguen un patrón definido. De 2016 a 2017 la temperatura media aumentó pero volvió a caer en el 2018.\n",
    "Incluso si observamos la distribución, vemos que en 2017 la temperatura osciló entre valores medios, mientras que para 2018 hay dos grandes picos, uno para temperaturas menores que 10 grados y otro para mayores a 25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Hay alguna relación entre las lluvias y la temperatura?\n",
    "\n",
    "Según el gráfico debajo no parecería que hubiera, aunque si se puede ver que los días que llueve poca cantidad son en general dias con temperaturas menores a 15 grados en promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = weather_data_copy[(weather_data_copy.precipitation > 0)]\n",
    "out = sns.scatterplot(x='precipitation', y='temp_media', data=tmp)\n",
    "plt.xlabel('Precipitaciones (mm)')\n",
    "plt.ylabel('Temperatura media')\n",
    "plt.title('Relación precipitaciones / Temperatura media')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo llueve según la estación del año?\n",
    "\n",
    "El gráfico debajo demuestra que en verano es cuando menos ha llovido en los últimos 4 años, sin contar el 2017 que fue la estación más lluviosa de ese año en cuanto a cantidad de mm. La primeavera es por lo general muy lluviosa y el invierno 2018 fue la estación que mas lluvia tuvo en volumen en los últimos 4 años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = weather_data_copy[(weather_data_copy.precipitation > 0) & (weather_data_copy.year != 2019)]\n",
    "plt.xlabel('Estación')\n",
    "plt.ylabel('Cantidad de precipitaciones (mm)')\n",
    "plt.title('Lluvias por estación últimos 2015 - 2019')\n",
    "plt.ylim(0,300) \n",
    "out = sns.barplot(x='season', y ='precipitation' , data=tmp, estimator = sum, hue='year', palette=\"Set1\", ci=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más alla de los mm de precipitaciones, `queremos ver cuantos días ha llovido cada año`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = weather_data_copy[(weather_data_copy.precipitation > 0) & (weather_data_copy.year != 2019)]\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "sns.set_style(\"whitegrid\")\n",
    "out = sns.countplot(x='year' , data=tmp, hue='year', palette=\"Set3\")\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Cantidad de días lluviosos')\n",
    "plt.title('Cantidad de dias con precipitaciones últimos 2015 - 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos en el gráfico en **2018 llovió aproximadamente el 30% de los días del año**, una diferencia considerable con los 3 años anteriores, incluso con el 2016 que también fue muy lluvioso (lluvias registradas poco menos de 100 días del año)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo es la distribución de la temperatura media?\n",
    "\n",
    "Como se puede visualizar en el gráfico, algunos meses con menos constantes en cuanto a sus temperaturas medias. Por ejemplo vemos que ésta varía mucho en meses de la primavera y el otoño, teniendo una menor fluctuación en invierno y en verano.\n",
    "\n",
    "Hay un par de outliers claramente en Agosto y Julio que no teníamos identificados antes de hacer esta gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = weather_data_copy\n",
    "sns.set_style(\"whitegrid\")\n",
    "rcParams['figure.figsize'] = 14, 10\n",
    "plt.title('Distribución historica 2015-2019 temperatura media por mes')\n",
    "sns.violinplot(x=\"month\", y=\"temp_media\", data=tmp);\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Temperatura media')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las mayores variaciones de temperatura entre la máxima y la mínima registrada en el día se dan en los meses de junio y Julio. Se registran altas temperaturas y disminuyen considerablemente en las madrugadas (Alrededor de 10 grados)\n",
    "\n",
    "Para ver estos datos creamos una nueva columna en el dataframe y graficamos el promedio mes a mes de esa diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['variacion_temperatura']  = tmp['temp_max'] - tmp['temp_min']\n",
    "out = sns.barplot(x='month', y ='variacion_temperatura' , data=tmp, estimator = np.mean, palette=\"Set2\", ci=0)\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Variación temperatura')\n",
    "plt.title('Variación entre temperatura maxima y minima en promedio mes a mes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardo en BD para TFM\n",
    "\n",
    "Aprovechando que se realizó la extracción de todos los datos, se almacenan en la BD destinada al TFM. `Está comentada la conexión para no volverlo a ejecutar sin querer`. **Por este motivo si se ejecuta da error**\n",
    "\n",
    "La dificultad que se tuvo acá fue no poder almacenar valores Nulos en la base de datos, daba error en el insert. Esto se solucionó modificando los valores NaN de las precipitaciones por 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino los outliers que identifiqué antes - 02/08/2017 y 20/07/2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def remove_Nan(element):\n",
    "    if math.isnan(element):\n",
    "        return 0\n",
    "    else:\n",
    "        return element\n",
    "\n",
    "\n",
    "weather_data_bd = pd.read_csv('../dat/all_weather_data.csv', sep = ',', index_col = 0)\n",
    "weather_data_bd['date'] = weather_data_bd.date.apply(cast_date)\n",
    "weather_data_bd['precipitation'] = weather_data_bd.precipitation.apply(remove_Nan)\n",
    "\n",
    "weather_data_bd = weather_data_bd[(weather_data_bd.date != datetime(2017,8,2)) & (weather_data_bd.date != datetime(2017,7,20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "#conn = pg.connect(\"postgres://xseeeed:LosTilosgfhfg1514@postgre-sqltest.cpdeokpzufj1.us-west-2.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "for index, row in weather_data_bd.iterrows():\n",
    "    insert_query = \"insert into weather_conditions(date, hour_temp_max, hour_temp_min, precipitation, temp_max, temp_media, temp_min, wind_speed, wind_speed_max) VALUES ('{0}', '{1}', '{2}', {3}, {4}, {5}, {6}, {7}, {8})\".format(row.date, row.hour_temp_max, row.hour_temp_min, row.precipitation,  row.temp_max, row.temp_media, row.temp_min, row.wind_speed, row.wind_speed_max)\n",
    "    cur.execute(insert_query)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
